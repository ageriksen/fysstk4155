\documentclass[12pt]{revtex4-2}
%\documentclass[12pt]{article}
\listfiles               %  print all files needed to compile this document

\usepackage{amsmath}
\usepackage{xparse}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{color}
\usepackage{physics}
\usepackage{algorithm2e}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{pgfplots}
\usepackage{pgfplotstable, booktabs, mathpazo}
\usepackage{natbib}

\pgfplotsset{compat=1.15}

\pgfplotstableset{
    every head row/.style={before row=\toprule \hline ,after row=\hline\hline \midrule},
    every last row/.style={after row=\hline \bottomrule},
    every first column/.style={
        column type/.add={|}{}
        },
    every last column/.style={
        column type/.add={}{|}
        },
}
\pgfplotstableset{
    every head row/.style={before row=\toprule \hline ,after row=\hline\hline \midrule},
    every last row/.style={after row=\hline \bottomrule}
}

%\begin{figure}[hbtp]
%\includegraphics[scale=0.4]{.pdf}
%\caption{}
%\label{fig:}
%\end{figure}

%\begin{tikzpicture}
%    \begin{axis}[
%            title= Earth-Sun system, Forward Euler integration,
%            xlabel={$x$},
%            ylabel={$y$},
%        ]
%        \addplot table {../runresults/earthEuler2body.dat}
%    \end{axis}
%\end{tikzpicture}

\begin{document}
\title{%
	project 1, FYS-STK4155 \\
	\large Regression and Resampling of Terrain data and the Franke function}
\author{A. G. Eriksen}
\date{\today}
\begin{abstract}
	The project motivation lies in exploring linear regression methods with regards 
	to simulated and real terrain data. \\
	The Ordinary Least Squares method has been explored for the simulated terrain, 
	both with and without resampling methods. \\
	The resampling methods used are the bootstrap and k-fold Cross validation 
	methods. \\
	The intent was to implement Ridge regression and Lasso regression for 
	the simulated data and then move on to the real terrain, but time ran out and 
	bugs kept popping up. The only data here are from the OLS
\end{abstract}
\maketitle
\tableofcontents

\section{introduction}
%The aims and rationales of the project. What we have done in the project. Brief 
%summary of structure of the report. 

The aim for the project was to explore regression methods for predicting an assumed 
functional dependence. To build up and test the methods we used a function called the
"Franke function"\cite{franke1979critical} to simulate a terrain and provide a definitive
functional dependency between the input data and the targets. \\

The initial regression was made using various polynomial interpolations as the basis, 
and studying the results of the fit for various models to try and map out error 
estimates in regards to the complexity of the models. \\

Once the simplest models were tested we added resampling of the generated data using the 
bootstrap method to improve and explore the accuracy of the models, exploring the bias-
variance trade-off in particular. \\

We move on to compare with a different, popular resampling method called k-fold Cross-
Validation(k-fold CV). This would provide some comparisons with the bootstrap method.

Following this, the intent was to implement a few more regression methods and explore
reductions in the variance of the model predictions from penalising specific features 
of the model, resulting in more stable predictions. Once this was done we could bring the
code to actual terrain data, whose assumed functional dependency we could not know, nor
really could guarantee and go over the various regression and resampling methods for 
the predictions. Time ran out and this remains unexplored. 

\section{method}
Theoretical models and technicalities

The basis for the regressions used here, is the Franke function\cite{franke1979critical}
\begin{align}
 f(x,y) &= \frac{3}{4}\exp{\left(-\frac{(9x-2)^2}{4} - \frac{(9y-2)^2}{4}\right)} 
	\nonumber\\
		&+\frac{3}{4}\exp{\left(-\frac{(9x+1)^2}{49}- \frac{(9y+1)}{10}\right)} 
	\nonumber\\
		&+\frac{1}{2}\exp{\left(-\frac{(9x-7)^2}{4} - \frac{(9y-3)^2}{4}\right)} 
	\nonumber\\
		&-\frac{1}{5}\exp{\left(-(9x-4)^2 - (9y-7)^2\right) }.
\label{franke}
\end{align}
The function is defined for values $x, y \in [0, 1]$. To make the simulation more 
authentic, noise can be added when generating the targets through the function, with a
normally distributed noise, $\varepsilon$. Here $\varepsilon$ follows a normal 
distribution of $\mathcal{N}(0, 1)$, $\sigma^2=1$. Though the strength of the noise can 
be varied to highlight statistical effects. \\

The input x and y values are generated as arrays, either through a normal distribution 
of numbers in the range and then sorted, or just as a range or linearly spaced array 
with a given amount of elements. Though to get a proper terrain grid, we need to mesh 
the 2 together. Once this is done, we generally flatten the arrays before working on 
them to simplify things. 

The regression model can be written as a matrix-vector product,
\begin{align}
	\tilde{y} = \mathbf{X}\beta.
\end{align}
This is based on an assumption that the target values are dependent on the input 
variables along a model like
\begin{align}
	\mathbf{y} = \mathbf{f(x)} + \varepsilon
\end{align}
This allows us to define a cost function dependent on $\beta$, it's derivative and the
optimal $\beta$:\cite{hastie2009elements} \cite{morten2020lecturenotes}
\begin{align}
	C(\bm{\beta}) &= \frac{1}{n} \big\{ ( \bm{y} - \bm{X}\bm{\beta} )^2 \big\} ,
	\label{costfunc}\\
	\pdv{C(\bm{\beta}}{\bm{\beta}} &= 0 = \bm{X^T}\qty(\bm{y} - \bm{X}\bm{\beta}), \\
	\bm{\hat{\beta}} &= \qty(\bm{X^T}\bm{X})^{-1} \bm{X^T}\bm{y}.
	 \label{betaoptimal}
\end{align}

With an expression for the optimal beta, we now have to find a way to build our 
feature matrix for a polynomial of the n-th degree, to allow for varying model 
complexity.

\begin{algorithm}
	\DontPrintSemicolon
	\KwIn{$\bm{x}$ and $\bm{y}$ and polynomial degree $n$}
	\KwOut{Feature matrix X with dimension $mxn$}
	$n \gets length(\bm{x})$\;
	$m \gets int((n+1)\cdot (n+2)/2)$\;
	$X \gets matrix.ones(nxm)$\;
	\For{$i \gets 1$ \textbf{to} $n+1$}{
		$q \gets int((i)*(i+1)/2)$\;	
		\For{$k \gets 0$ \textbf{to} $i+1$}{
			$X_{(:, q+k)} \gets x^{i-k}\cdot y^k$\;
		}
	}
	\Return{$X$}\;
\caption{make feature matrix X given input $\vec{x}, \vec{y}$ and dimension n}
\label{alg:design}
\end{algorithm}
with an algorithm for the feature matrix and a set of targets generated by the Franke 
function we just need to fit the features and predict an output. Following this, we can 
apply various statistics to compare the model to the targets. These would include
\begin{align}
	MSE(y, \tilde{y}) &= \frac{1}{n}\sum_{i=0}^{n-1}(y_i - \tilde{y_i})^2
		= \mathbb{E}[(y - \tilde{y})^2],
		\label{MSE} \\
	R^2(y, \tilde{y}) &= 1 - \frac{\sum_{i=0}^{n-1}(y_i - \tilde{y_i})^2}
		{\sum_{i=0}^{n-1}(y_i - \mathbb{E}[y])^2} 
		\label{R2}, \\
	\mathbb{E}[y] &= \frac{1}{n}\sum_{i=0}^{n-1} y_i \label{mean}, \\
	\mathbb{E}[(y - \tilde{y})^2] 
		&=...= \mathbb{E}[(y -\mathbb{E}[\tilde{y}])^2] 
			+ \mathbb{E}[(\tilde{y} - \mathbb{E}[\tilde{y}])^2] 
			+ \sigma^2 \label{bias-variance-error}, \\
	\mathbf{Bias}(y, \tilde{y} &= \mathbb{E}[(y -\mathbb{E}[\tilde{y}])^2] ,
		\label{bias} \\
	\mathbf{Var}(\tilde{y}) &= \mathbb{E}[(\tilde{y} - \mathbb{E}[\tilde{y}])^2] ,
		\label{variance} \\
	MSE(y, \tilde{y}) &= \mathbf{Bias}(y, \tilde{y}) + \mathbf{Var}(\tilde{y}) + \sigma^2
		\label{bias-variance}.
\end{align}

Moving on from this, we can begin to refine the data we have somewhat, using resampling 
methods. The ones we will make use of, are Bootstrap and k-fold Cross Validation. 
The essence here, is that we have a limited data set. To compensate for this, methods of
selecting which data to run allows us to make the best use of what data we do have. 
The main methods discussed here are Bootstrap[\ref{alg:bootstrap}] and k-fold Cross 
Validation[\ref{alg:kfoldCV}]

\begin{algorithm}
	\DontPrintSemicolon
	\KwIn{feature matrix, $X$, targets, $y$, and number of bootstraps, $N$}
	\KwOut{model fits and predictions}
	$\bm{\tilde{y}^{fit}} \gets \mathbf{array}(N)$\;
	$\bm{\tilde{y}^{predict}} \gets \mathbf{array}(N)$\;
	$\bm{\beta} \gets \mathbf{array}(N)$\;
	\For{$i \gets 0$ \textbf{to} $N$}{
		Shuffle $X$ and $y$\;
		Split data into training and test sets\;
		$\beta \gets OLS(X_{train}, y_{train})$\;
		$\tilde{y}_i^{fit} \gets \bm{X_{train}}\bm{\beta}$\;
		$\tilde{y}_i^{predict} \gets \bm{X_{test}}\bm{\beta}$\;
	}
	\Return{$\bm{\beta}$, $\bm{\tilde{y}_{fit}}$, $\bm{\tilde{y}_{predict}}$}
	\caption{The Bootstrap method of resampling. This method makes no distinction
	between resamplings, using the assumption that the initial set follows a 
	distribution the resampling is mimicing. Thus, the values approaches a better 
	interpretation}
	\label{alg:bootstrap}
\end{algorithm}

\begin{algorithm}
	\DontPrintSemicolon
	\KwIn{feature matrix, $\bm{X}$, targets, $\bm{y}$, and number of folds, $k$}
	\KwOut{model fits and predictions}
	$\tilde{y}^{fit} \gets \mathbf{array}(k)$\;
	$\tilde{y}^{predict} \gets \mathbf{array}(k)$\;
	$\bm{\beta} \gets \mathbf{array}(k)$\;
	Split $k$ folds $\bm{\mu}, \bm{\nu} \subset \bm{X}, \bm{y}$\;
	\For{$i \gets 0$ \textbf{to} $k$}{
		$\bm{X^{test}} \gets \bm{X}\{\mu_i\}$\;
		$\bm{X^{train}} \gets \bm{X}\{\bm{\mu} - \mu_i\}$\;
		$\bm{y^{test}} \gets \bm{y}\{\nu_i\}$\;
		$\bm{y^{train}} \gets \bm{y}\{\bm{\nu} - \nu_i\}$\;
		$\beta \gets OLS(X_{train}, y_{train})$\;
		$\tilde{y}_i^{fit} \gets \bm{X_{train}}\bm{\beta}$\;
		$\tilde{y}_i^{predict} \gets \bm{X_{test}}\bm{\beta}$\;
	}
	\Return{$\bm{beta}$, $\bm{\tilde{y}^{fit}}$, $\bm{\tilde{y}^{predict}}$}
	\caption{k-fold Cross Validation method of resampling. This allows us to vary the 
	combination of the shuffled indices without reusing datapoints.}
	\label{alg:kfoldCV}
\end{algorithm}

Finally, we can also look more closely at the regression method we use. The Ordinary 
Least Squares solution works OK, but there are issues, for instance if $(X^TX)^{-1}$
were to be singular, then the method would fail. A solution to this lies in methods
such as Ridge regression and Lasso regression. The solution to the possibility of 
the singular values lies in adding something along the diagonal, so
$(X^TX + \lambda\mathbb{I})^{-1}$\\

This complicates the expression for MSE somewhat, due to this addition. A rewrite of the 
MSE, could be made using the "norm-2" description to
\begin{align}
	\min_{\beta\in\mathbb{R}^p} =
		\frac{1}{n} \sum_{i=0}^{n-1} (y_i - \tilde{y}_i)^2 
		\frac{1}{n} \norm{\bm{y} - \bm{X\beta}}_2^2.
\end{align}
If we were to add our extra parameter here, we could 
\begin{align}
	\min_{\beta\in\mathbb{R}^p}\qq{} \frac{1}{n}\norm{\bm{y} - \bm{X\beta}}_2^2 
		+	\lambda\norm{\bm{\beta}}_2^2
\end{align}
Which gives us what we call Ridge regression, or we could use "norm-1" to set
\begin{align}
	\min_{\beta\in\mathbb{R}^p}\qq{} \frac{1}{n}\norm{\bm{y} - \bm{X\beta}}_2^2 
		+	\lambda\norm{\bm{\beta}}_1.
\end{align}
Each of these represent various ways to ensure we get a minimum. The effects differ 
somewhat between them, where Ridge "penalizes" some betas according to the amount of
variance in the system, Lasso strikes these out, setting them to 0, while keeping the 
unaffected $\beta$'s essentially the same. \\

The code is set up so that a mesh of 2 matrices are fed into the franke function and
then all thre are flattened into 1 dimension. Then they are fed into a resampling and
regression function where the above mentioned mathematics takes place and after this, 
the resulting fit and predictions for the target values are subjected to various error
tests, such as MSE, R2 score and bias-variance estimations

With regards to the bias-variance estimations and their relationship to the error 
estimate can be expressed

\begin{align}
    & C(\mathbf{\hat{X}}, \vec{\beta}) 
		 = \frac{1}{n} \sum_{i=0}^{n-1}(y_i - \tilde{y}_i)^2
		 \,=\, \mathbb{E}[(y- \tilde{y})^2]
\end{align}
using the values for: $y = f(x) + \varepsilon$, $f(x) \equiv f$, 
$\ev{\varepsilon} \equiv 0$ and $var(\varepsilon)\equiv \sigma^2$, as well as adding and
subtracting $\mathbb{E}[\bm{\tilde{y}}]$
\begin{align}
	\mathbb{E}[(y- \tilde{y})^2] 
	&	= \mathbb{E}[(y - \tilde{y} + \mathbb{E}[\bm{\tilde{\tilde{y}}}] 
		- \mathbb{E}[\bm{\tilde{y}}])^2] \nonumber \\
	&= \mathbb{E}[(f-\ev{\tilde{y}})^2] 
	+ \mathbb{E}[(\tilde{y} - \ev{\tilde{y}})^2] 
	+ \mathbb{E}[\varepsilon^2] \nonumber\\
	&+ 2\mathbb{E}[(f-\mathbb{E}[\bm{\tilde{y}}])(\bm{\tilde{y}} 
		- \mathbb{E}[\bm{\tilde{y}}])] \nonumber\\
	&+ 2\mathbb{E}[\varepsilon(f-\ev{\tilde{y}})] 
	+ 2\mathbb{E}[\varepsilon(\bm{\tilde{y}} - \mathbb{E}[\tilde{y}])]
\end{align}
Here we have 2 parts with the expectation value of our noise variable, which can be 
separated out ab both $\bm{f}$, $\bm{\tilde{y}}$ and $\bm{\tilde{y}}$ are assumed
deterministic. Since the noise has a mean value of $0$, these parts dissapear. 
Additionally, $\mathbb{E}[\varepsilon]=\sigma^2$.
\begin{align}
	= \mathbb{E}[(f-\ev{\tilde{y}})^2] 
	+ \mathbb{E}[(\tilde{y} - \ev{\tilde{y}})^2] 
	+ \mathbb{E}[\varepsilon^2]
	+ 2\mathbb{E}[(f-\mathbb{E}[\bm{\tilde{y}}])
\end{align}
Next bit requires a little bit of work, but 
Wolframalpha\cite{wolframalpha2020expval} lets us set 
$\mathbb{E}[f\cdot\bm{\tilde{y}}]$, which we can separate as they're both deterministic
so, $ \mathbb{E}[f]\mathbb{E}[\bm{\tilde{y}}] - \mathbb{E}[\bm{\tilde{y}}]^2 $, which
cancels out, seeing as both the function and the approximation share an expected value
given the initial assumption of the model. This leaves us with 
\begin{align}
	\mathbb{E}[(y- \tilde{y})^2] 
	= \mathbb{E}[(f-\ev{\tilde{y}})^2] 
	+ \mathbb{E}[(\tilde{y} - \ev{\tilde{y}})^2] 
	+ \mathbb{E}[\varepsilon^2]
     = Bias[\tilde{y}] + Var[\tilde{y}] - \sigma^2.
\end{align}
The bias, variance and noise variance is in order here. The bias represents an offset
between the model mean and the target values, the variance is a measure of the spread of
the models with regards to the mean of all the models, while the noise variance is 
generally unknown and harder to pin down. 

\section{results}
%Results of study and discussion of results

In essence, these regressions are performed to make a model of and predict the shape of
(simulated) terrain. While most of the simulations here have been performed with a
much more significant level of noise added on to the base function, the surface shown
can be seen in figure \ref{fig:FrankeSurface}

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{../plots/surfaceplotfrankeSigma01.png}
\caption{Surface plot of the simulated surface generated through the Franke function
	The inputs and outputs are both unitless, so the axes are merely ilustrative. 
	This figure was generated using a slight amount of noise added to the function, 
	which is the source of the slight irregularities observed. The variance of the 
	noise was set to $0.01$ for the sake of illustrating the surface, while most of the 
	results taken from the function uses a variance of 1, which makes the structures 
	seen here obscured.}
\label{fig:FrankeSurface}
\end{figure}

For the most basic implementation of regression, with no regard for the possibility of a
singular matrix and with the assumption of a large enough data set that the prediction 
is accurate. Here, we set up the data and prepare several different models, based on the
degree of the polynomial we want to use to make our fit. To visualise the accuracy of 
the fit, a plot of the MSE for the fit to the training data and the test data are set up.


\begin{figure}[hbtp]
\includegraphics[scale=0.7]{../plots/frankeOLSMSEsigma1maxdeg20.png}
\caption{Plot of the MSE for OLS regression of the Franke function with no resampling
	techniques active. The worst fit is for the straight line case, where the MSE lies
	at about a 1, with a rapid reduction which smooths out around 5th degree polynomial
	for the test set, while the training fit continues to improve. 
	Couple of notices here, is the floating point numbers that represent the model 
	complexity or polynomial degree. They should be integers. In addition, there was 
	no real fit for the 0th degree polynomial, and the starting point here is not 
	accurate}
\label{fig:MseNoResample}
\end{figure}

Following after these, there was the issue of implementing resampling methods. Since 
these also give us several fits of the model, we can also evaluate the variance of the
models across tries to produce a bias-variance plot,

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt1e6test.png}
\caption{
	Here we have the bias and variance plot of a run with bootstrap, running $1e3$ 
	resamplings over $1e6$ data points with a noise strength of $1$ and fitting to the training
	set. We see that the bias starts out very high and gradually increases. The variance begins 
	very small, and then slowly increases. The summed up error roughly follows the 2, but there 
	is a distinct difference in the behaviour for the error here and in figure 
	\ref{fig:MseNoResample} with regards to the error's behaviour over the model's increasing 
	complexity. 
	}
\label{fig:BootstrapBiasVariance1e6test}
\end{figure}
Figure \ref{fig:BootstrapBiasVariance1e6test} shows a high and increasing bias and a slowly
growing variance over the model complexity kept the same as in figure 
\ref{fig:MseNoResample}.

This is largely the extent of gathered data. Further examples of the bias variance 
results should be in the appendix. 

\section{conclusion}
%Beyond discussion, this is actually concluding things. 
%perspectives of study

The setup of the Franke function as well as the surface plot of the generated data was 
largely taken from the project description and looks about as you'd expect. The example 
with no resampling and Ordinary least squares also behaves as we would expect, where the 
initial bias of the linear fit drops off as we introduce complexity until the point 
where the variance's exponential growth overtakes the dropping bias and we see the test 
error increase. \\

For some reason, this seems to not be the case when the Bootstrap method is introduced, 
as we see in figure \ref{fig:BootstrapBiasVariance1e6test}.  Here, the bias doesn't fall off 
for some reason and the variance hardly increases at all compared to the increase in 
error we saw when looking at the simplest case. This could be an error in the calculation
of the new measurements, with the number of fits per model degre of complexity increases. 
Perhaps it's an error regarding the dimensionality along which we took the means for the
difference in the bias and variance. Mixing up the rows and collumns as it were. \\

That said, there were several things wrong in the code, and while I eventually managed to 
finish a calculation using the k-fold cross validation, the amount or repeated code showed
it's toll in strange errors. Though the code was attempted cleaned up and object oriented 
in order to reduce copying code and making the usecase more general, especially wrt.
including the real terrain data. These attempts did not bear fruit, unfortunately, as when
I finally managed to get a working example of the simplest case, the results were strange, 
even just the measure of the MSE. 

Another issue I encountered was difficulties in selecting which data to keep. The 
$\bm{\beta}$ coefficients would definitely be a good idea. Perhaps also the train and
test indices, as well as the training and test fits of the model. I did not settle on a 
method I was happy with. Further usefull data, not the least in the case of plots were the
MSE, bias, etc. which would need to be stored or used for each iteration of each of the 
varying parameters. 

I'd think the main improvement for this project would be a more carefully setup, object
oriented design so that the varying resampling and regression methods would be more 
easily changed without retyping so many initial variables and data, as these quickly 
accumulated errors and made the code very tiresome to navigate. Further, this would 
make entering in the actual terrain data much easier and would help guarantee the results
could be comparable between the to usecases given no changes were made to the code running
on the data sets.

\section{appendix}
%extra material, e.g. superfluous code, tables and figures not fitting into the text itself.


\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt1e4test.png}
\caption{
	Bias, variance and error for the bootstrap resampling of the franke data fitted to 
	the test set. $1e3$ bootstraps and $1e4$ data points input. 
	}
\label{fig:BootstrapBiasVariance1e4test}
\end{figure}

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt1e4train.png}
\caption{
	Bias, variance and error for the bootstrap resampling of the franke data fitted to 
	the train set. $1e3$ bootstraps and $1e4$ data points input. 
	}
\label{fig:BootstrapBiasVariance1e4train}
\end{figure}

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt2e4test.png}
\caption{
	Bias, variance and error for the bootstrap resampling of the franke data fitted to 
	the test set. $1e3$ bootstraps and $2e4$ data points input. 
	}
\label{fig:BootstrapBiasVariance2e4test}
\end{figure}

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt2e4train.png}
\caption{
	Bias, variance and error for the bootstrap resampling of the franke data fitted to 
	the train set. $1e3$ bootstraps and $2e4$ data points input. 
	}
\label{fig:BootstrapBiasVariance2e4train}
\end{figure}

\begin{figure}[hbtp]
\includegraphics[scale=0.7]{
	../plots/frankeBootstrapBiasVariancesigma1poly10boot1e3datapt1e6train.png}
\caption{
	Bias, variance and error for the bootstrap resampling of the franke data fitted to 
	the train set. $1e3$ bootstraps and $1e6$ data points input. 
	}
\label{fig:BootstrapBiasVariance1e6test}
\end{figure}

\bibliography{bib.bib}
\end{document}

